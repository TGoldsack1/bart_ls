usage: train.py [-h] [--no-progress-bar] [--log-interval LOG_INTERVAL]
                [--log-format {json,none,simple,tqdm}] [--log-file LOG_FILE]
                [--tensorboard-logdir TENSORBOARD_LOGDIR]
                [--wandb-project WANDB_PROJECT] [--azureml-logging]
                [--seed SEED] [--cpu] [--tpu] [--bf16]
                [--memory-efficient-bf16] [--fp16] [--memory-efficient-fp16]
                [--fp16-no-flatten-grads] [--fp16-init-scale FP16_INIT_SCALE]
                [--fp16-scale-window FP16_SCALE_WINDOW]
                [--fp16-scale-tolerance FP16_SCALE_TOLERANCE]
                [--on-cpu-convert-precision] [--min-loss-scale MIN_LOSS_SCALE]
                [--threshold-loss-scale THRESHOLD_LOSS_SCALE] [--amp]
                [--amp-batch-retries AMP_BATCH_RETRIES]
                [--amp-init-scale AMP_INIT_SCALE]
                [--amp-scale-window AMP_SCALE_WINDOW] [--user-dir USER_DIR]
                [--empty-cache-freq EMPTY_CACHE_FREQ]
                [--all-gather-list-size ALL_GATHER_LIST_SIZE]
                [--model-parallel-size MODEL_PARALLEL_SIZE]
                [--quantization-config-path QUANTIZATION_CONFIG_PATH]
                [--profile] [--reset-logging] [--suppress-crashes]
                [--use-plasma-view] [--plasma-path PLASMA_PATH]
                [--tokenizer {moses,nltk,space}]
                [--bpe {byte_bpe,bytes,characters,fastbpe,gpt2,bert,hf_byte_bpe,sentencepiece,subword_nmt}]
                [--optimizer {adadelta,adafactor,adagrad,adam,adamax,composite,cpu_adam,lamb,nag,sgd}]
                [--lr-scheduler {cosine,fixed,inverse_sqrt,manual,pass_through,polynomial_decay,reduce_lr_on_plateau,step,tri_stage,triangular}]
                [--scoring {sacrebleu,bleu,chrf,wer}]
                [--criterion {adaptive_loss,composite_loss,cross_entropy,ctc,fastspeech2,hubert,label_smoothed_cross_entropy,latency_augmented_label_smoothed_cross_entropy,label_smoothed_cross_entropy_with_alignment,legacy_masked_lm_loss,masked_lm,model,model_based_denoising,nat_loss,sentence_prediction,sentence_ranking,tacotron2,wav2vec,vocab_parallel_cross_entropy}]
                [--task TASK] [--num-workers NUM_WORKERS]
                [--skip-invalid-size-inputs-valid-test]
                [--max-tokens MAX_TOKENS] [--batch-size BATCH_SIZE]
                [--required-batch-size-multiple REQUIRED_BATCH_SIZE_MULTIPLE]
                [--required-seq-len-multiple REQUIRED_SEQ_LEN_MULTIPLE]
                [--dataset-impl {raw,lazy,cached,mmap,fasta,huffman}]
                [--data-buffer-size DATA_BUFFER_SIZE]
                [--train-subset TRAIN_SUBSET] [--valid-subset VALID_SUBSET]
                [--combine-valid-subsets] [--ignore-unused-valid-subsets]
                [--validate-interval VALIDATE_INTERVAL]
                [--validate-interval-updates VALIDATE_INTERVAL_UPDATES]
                [--validate-after-updates VALIDATE_AFTER_UPDATES]
                [--fixed-validation-seed FIXED_VALIDATION_SEED]
                [--disable-validation] [--max-tokens-valid MAX_TOKENS_VALID]
                [--batch-size-valid BATCH_SIZE_VALID]
                [--max-valid-steps MAX_VALID_STEPS] [--curriculum CURRICULUM]
                [--gen-subset GEN_SUBSET] [--num-shards NUM_SHARDS]
                [--shard-id SHARD_ID]
                [--distributed-world-size DISTRIBUTED_WORLD_SIZE]
                [--distributed-num-procs DISTRIBUTED_NUM_PROCS]
                [--distributed-rank DISTRIBUTED_RANK]
                [--distributed-backend DISTRIBUTED_BACKEND]
                [--distributed-init-method DISTRIBUTED_INIT_METHOD]
                [--distributed-port DISTRIBUTED_PORT] [--device-id DEVICE_ID]
                [--distributed-no-spawn]
                [--ddp-backend {c10d,fully_sharded,legacy_ddp,no_c10d,pytorch_ddp,slow_mo}]
                [--ddp-comm-hook {none,fp16}] [--bucket-cap-mb BUCKET_CAP_MB]
                [--fix-batches-to-gpus] [--find-unused-parameters]
                [--gradient-as-bucket-view] [--fast-stat-sync]
                [--heartbeat-timeout HEARTBEAT_TIMEOUT] [--broadcast-buffers]
                [--slowmo-momentum SLOWMO_MOMENTUM]
                [--slowmo-algorithm SLOWMO_ALGORITHM]
                [--localsgd-frequency LOCALSGD_FREQUENCY]
                [--nprocs-per-node NPROCS_PER_NODE]
                [--pipeline-model-parallel]
                [--pipeline-balance PIPELINE_BALANCE]
                [--pipeline-devices PIPELINE_DEVICES]
                [--pipeline-chunks PIPELINE_CHUNKS]
                [--pipeline-encoder-balance PIPELINE_ENCODER_BALANCE]
                [--pipeline-encoder-devices PIPELINE_ENCODER_DEVICES]
                [--pipeline-decoder-balance PIPELINE_DECODER_BALANCE]
                [--pipeline-decoder-devices PIPELINE_DECODER_DEVICES]
                [--pipeline-checkpoint {always,never,except_last}]
                [--zero-sharding {none,os}] [--no-reshard-after-forward]
                [--fp32-reduce-scatter] [--cpu-offload] [--use-sharded-state]
                [--arch ARCH] [--max-epoch MAX_EPOCH]
                [--max-update MAX_UPDATE] [--stop-time-hours STOP_TIME_HOURS]
                [--clip-norm CLIP_NORM] [--sentence-avg]
                [--update-freq UPDATE_FREQ] [--lr LR]
                [--stop-min-lr STOP_MIN_LR] [--use-bmuf] [--save-dir SAVE_DIR]
                [--restore-file RESTORE_FILE]
                [--finetune-from-model FINETUNE_FROM_MODEL]
                [--reset-dataloader] [--reset-lr-scheduler] [--reset-meters]
                [--reset-optimizer]
                [--optimizer-overrides OPTIMIZER_OVERRIDES]
                [--save-interval SAVE_INTERVAL]
                [--save-interval-updates SAVE_INTERVAL_UPDATES]
                [--keep-interval-updates KEEP_INTERVAL_UPDATES]
                [--keep-interval-updates-pattern KEEP_INTERVAL_UPDATES_PATTERN]
                [--keep-last-epochs KEEP_LAST_EPOCHS]
                [--keep-best-checkpoints KEEP_BEST_CHECKPOINTS] [--no-save]
                [--no-epoch-checkpoints] [--no-last-checkpoints]
                [--no-save-optimizer-state]
                [--best-checkpoint-metric BEST_CHECKPOINT_METRIC]
                [--maximize-best-checkpoint-metric] [--patience PATIENCE]
                [--checkpoint-suffix CHECKPOINT_SUFFIX]
                [--checkpoint-shard-count CHECKPOINT_SHARD_COUNT]
                [--load-checkpoint-on-all-dp-ranks]
                [--write-checkpoints-asynchronously] [--store-ema]
                [--ema-decay EMA_DECAY] [--ema-start-update EMA_START_UPDATE]
                [--ema-seed-model EMA_SEED_MODEL]
                [--ema-update-freq EMA_UPDATE_FREQ] [--ema-fp32]
                [--activation-fn {relu,gelu,gelu_fast,gelu_accurate,tanh,linear}]
                [--dropout DROPOUT] [--attention-dropout ATTENTION_DROPOUT]
                [--activation-dropout ACTIVATION_DROPOUT] [--adaptive-input]
                [--encoder-embed-path ENCODER_EMBED_PATH]
                [--encoder-embed-dim ENCODER_EMBED_DIM]
                [--encoder-ffn-embed-dim ENCODER_FFN_EMBED_DIM]
                [--encoder-layers ENCODER_LAYERS]
                [--encoder-attention-heads ENCODER_ATTENTION_HEADS]
                [--encoder-normalize-before] [--encoder-learned-pos]
                [--encoder-layerdrop ENCODER_LAYERDROP]
                [--encoder-layers-to-keep ENCODER_LAYERS_TO_KEEP]
                [--max-source-positions MAX_SOURCE_POSITIONS]
                [--decoder-embed-path DECODER_EMBED_PATH]
                [--decoder-embed-dim DECODER_EMBED_DIM]
                [--decoder-ffn-embed-dim DECODER_FFN_EMBED_DIM]
                [--decoder-layers DECODER_LAYERS]
                [--decoder-attention-heads DECODER_ATTENTION_HEADS]
                [--decoder-normalize-before] [--decoder-learned-pos]
                [--decoder-layerdrop DECODER_LAYERDROP]
                [--decoder-layers-to-keep DECODER_LAYERS_TO_KEEP]
                [--decoder-output-dim DECODER_OUTPUT_DIM]
                [--max-target-positions MAX_TARGET_POSITIONS]
                [--share-decoder-input-output-embed] [--share-all-embeddings]
                [--no-token-positional-embeddings]
                [--adaptive-softmax-cutoff ADAPTIVE_SOFTMAX_CUTOFF]
                [--adaptive-softmax-dropout ADAPTIVE_SOFTMAX_DROPOUT]
                [--adaptive-softmax-factor ADAPTIVE_SOFTMAX_FACTOR]
                [--layernorm-embedding] [--tie-adaptive-weights]
                [--tie-adaptive-proj] [--no-scale-embedding]
                [--checkpoint-activations] [--offload-activations]
                [--no-cross-attention] [--cross-self-attention]
                [--quant-noise-pq QUANT_NOISE_PQ]
                [--quant-noise-pq-block-size QUANT_NOISE_PQ_BLOCK_SIZE]
                [--quant-noise-scalar QUANT_NOISE_SCALAR]
                [--min-params-to-wrap MIN_PARAMS_TO_WRAP] [--char-inputs]
                [--relu-dropout RELU_DROPOUT] [--base-layers BASE_LAYERS]
                [--base-sublayers BASE_SUBLAYERS]
                [--base-shuffle BASE_SHUFFLE] [--export]
                [--no-decoder-final-norm] [--alibi]
                [--truncate-alibi TRUNCATE_ALIBI] [--use-xformers]
                [--attention-name ATTENTION_NAME]
                [--xformer-config XFORMER_CONFIG]
                [--pooling-layers POOLING_LAYERS] [--pooler-dropout D]
                [--pooler-activation-fn {relu,gelu,gelu_fast,gelu_accurate,tanh,linear}]
                [--spectral-norm-classification-head]
                [--restrict-position-embed] [--sliding-window]
                [--block-attention] [--top-down] [--dual_graph_encoder]
                [--source-lang SOURCE_LANG] [--target-lang TARGET_LANG]
                [--load-alignments] [--left-pad-source] [--left-pad-target]
                [--upsample-primary UPSAMPLE_PRIMARY] [--truncate-source]
                [--truncate-target] [--query-based]
                [--max-query-positions MAX_QUERY_POSITIONS]
                [--pad-query PAD_QUERY] [--input-pattern INPUT_PATTERN]
                [--block-size BLOCK_SIZE]
                [--num-batch-buckets NUM_BATCH_BUCKETS] [--eval-rouge]
                [--eval-rouge-args EVAL_ROUGE_ARGS]
                [--eval-rouge-detok EVAL_ROUGE_DETOK]
                [--eval-rouge-detok-args EVAL_ROUGE_DETOK_ARGS]
                [--eval-rouge-remove-bpe [EVAL_ROUGE_REMOVE_BPE]]
                [--eval-rouge-print-samples] [--custom-dict CUSTOM_DICT]
                [--adam-betas ADAM_BETAS] [--adam-eps ADAM_EPS]
                [--weight-decay WEIGHT_DECAY] [--use-old-adam]
                [--fp16-adam-stats] [--warmup-updates WARMUP_UPDATES]
                [--force-anneal FORCE_ANNEAL]
                [--end-learning-rate END_LEARNING_RATE] [--power POWER]
                [--total-num-update TOTAL_NUM_UPDATE] [--pad PAD] [--eos EOS]
                [--unk UNK] [--label-smoothing LABEL_SMOOTHING]
                [--report-accuracy] [--ignore-prefix-size IGNORE_PREFIX_SIZE]
                data
train.py: error: unrecognized arguments:  #4
scripts/summarization/my_ft_summ_v100.sh: line 52: --skip-invalid-size-inputs-valid-test: command not found
